import asyncio
import json
import base64
import time
import os
import numpy as np
import nats
from nats.errors import TimeoutError
from faster_whisper import WhisperModel
from logger import setup_logger
from src.config import Config

DEVICE = os.getenv("ASR_DEVICE", "cuda")
COMPUTE_TYPE = os.getenv("ASR_COMPUTE_TYPE", "float16")

logger = setup_logger("asr-worker")


class ASRWorker:
    def __init__(self):
        self.nc = None
        self.js = None
        self.model = None

    def load_model(self):
        print(f"â³ [ASR Worker] Loading Whisper Model ({DEVICE}/{COMPUTE_TYPE})...")
        try:
            self.model = WhisperModel("tiny", device=DEVICE, compute_type=COMPUTE_TYPE)
            print("âœ… [ASR Worker] Model Loaded successfully!")
        except Exception as e:
            print(f"âŒ [ASR Worker] CRITICAL: Model load failed - {e}")
            exit(1)

    def run_inference(self, audio_np, previous_text=""):
        if not self.model:
            return ""

        segments, info = self.model.transcribe(
            audio_np,
            beam_size=1,
            language="en",
            initial_prompt=previous_text,
            condition_on_previous_text=True,
            vad_filter=True,
        )
        result_text = "".join([s.text for s in segments])
        return result_text

    async def process_msg(self, msg):
        """
        process single NATS message
        message: {
            "req_id": "uuid...",
            "session_id": "user-session-123",
            "audio_b64": "base64_encoded_string...",
            "previous_text": "ä¸Šä¸€æ¬¡è¯†åˆ«çš„ç»“æœ...",
            "timestamp": 1234567890
        }
        """
        try:
            payload = json.loads(msg.data.decode())
            req_id = payload.get("req_id", "unknown")
            session_id = payload.get("session_id", "unknown")

            logger.info(f"Start inference", extra={"req_id": req_id})
            start_time = time.time()

            # 1. è§£ç éŸ³é¢‘ (Base64 -> Float32 Numpy)
            audio_bytes = base64.b64decode(payload["audio_b64"])
            audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
            audio_float32 = audio_int16.astype(np.float32) / 32768.0

            # 2. è·å–ä¸Šä¸‹æ–‡ (Prompt)
            # åœ¨åˆ†å¸ƒå¼æ¶æ„ä¸­ï¼Œä¸Šä¸‹æ–‡æœ€å¥½ç”±ç½‘å…³ç»´æŠ¤å¹¶ä¼ è¿‡æ¥ï¼ŒWorker ä¿æŒæ— çŠ¶æ€
            previous_text = payload.get("previous_text", "")

            # 3. æ‰§è¡Œæ¨ç† (è·‘åœ¨çº¿ç¨‹æ± ä¸­ï¼Œé¿å…é˜»å¡ asyncio å¾ªç¯)
            loop = asyncio.get_running_loop()
            new_text = await loop.run_in_executor(
                None, self.run_inference, audio_float32, previous_text
            )

            latency = round(time.time() - start_time, 3)
            logger.info(f"Inference done", extra={"req_id": req_id, "latency": latency})

            # 4. å¦‚æœæœ‰è¯†åˆ«ç»“æœï¼Œå‘å¸ƒåˆ°è¾“å‡ºé˜Ÿåˆ—
            if new_text.strip():
                print(f"âœ… Result [{session_id}]: '{new_text}' ({latency}s)")

                output_payload = {
                    "req_id": req_id,
                    "session_id": session_id,
                    "text": new_text,
                    "latency": latency,
                    "timestamp": time.time(),
                    # å¯ä»¥åœ¨è¿™é‡ŒæŠŠ audio_b64 å†æ¬¡ä¼ ä¸‹å»ï¼Œç»™å­˜å‚¨æœåŠ¡å­˜ MinIO
                    # æˆ–è€…å­˜å‚¨æœåŠ¡ç›´æ¥è®¢é˜… asr.input ä¹Ÿå¯ä»¥
                    "audio_b64": payload["audio_b64"],
                }

                # å‘å¸ƒåˆ° 'asr.output'ï¼Œä¾›ï¼š
                # 1. å­˜å‚¨æœåŠ¡ (Storage Worker) å­˜æ•°æ®åº“
                # 2. ç½‘å…³æœåŠ¡ (Gateway) å‘å›ç»™å‰ç«¯
                await self.js.publish("asr.output", json.dumps(output_payload).encode())

            # 5. ç¡®è®¤æ¶ˆæ¯ (Ack)
            await msg.ack()

        except Exception as e:
            print(f"âŒ Error processing message: {e}")
            # å¦‚æœæ˜¯æ•°æ®æ ¼å¼é”™è¯¯ï¼Œå»ºè®® Ack æ‰ï¼Œå¦åˆ™ NATS ä¼šä¸€ç›´é‡å‘å¯¼è‡´æ­»å¾ªç¯
            # å¦‚æœæ˜¯ä¸´æ—¶æ•…éšœï¼Œå¯ä»¥ msg.nak()
            await msg.ack()

    async def start(self):
        # 1. åŠ è½½æ¨¡å‹
        self.load_model()

        # 2. è¿æ¥ NATS
        print(f"ğŸ”Œ Connecting to NATS: {Config.NATS_URL}")
        self.nc = await nats.connect(Config.NATS_URL)
        self.js = self.nc.jetstream()

        # 3. åˆ›å»º Stream (å¦‚æœä¸å­˜åœ¨)
        # è¿™é‡Œç›‘å¬ asr.input.*
        try:
            await self.js.add_stream(name="ASR_INPUT", subjects=["asr.input"])
        except Exception:
            pass  # Stream å¯èƒ½å·²å­˜åœ¨

        # 4. å¯åŠ¨è®¢é˜… (Queue Group)
        # å…³é”®ç‚¹ï¼šä½¿ç”¨ queue="asr_workers"
        # è¿™æ ·å¦‚æœä½ å¯åŠ¨äº† 3 ä¸ª ASR Worker å‰¯æœ¬ï¼ŒNATS ä¼šè‡ªåŠ¨è´Ÿè½½å‡è¡¡ï¼Œ
        # æ¯æ¡éŸ³é¢‘åªä¼šè¢«ä¸€ä¸ª Worker å¤„ç†ï¼Œä¸ä¼šé‡å¤ã€‚
        sub = await self.js.subscribe(
            "asr.input", queue="asr_workers", cb=self.process_msg, manual_ack=True
        )

        print("ğŸš€ ASR Worker started! Waiting for audio chunks...")

        # ä¿æŒè¿è¡Œ
        try:
            await asyncio.Future()  # Run forever
        except asyncio.CancelledError:
            pass
        finally:
            await self.nc.close()


if __name__ == "__main__":
    worker = ASRWorker()
    try:
        asyncio.run(worker.start())
    except KeyboardInterrupt:
        print("ğŸ›‘ Worker stopped.")
